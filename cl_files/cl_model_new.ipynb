{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv files\n",
    "df = pd.read_csv('cl_Resources/home_value_calc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['commute time car'], axis=1)\n",
    "df = df.drop(['Zipcode', 'zip_code','latitude', 'longitude', 'city', 'state', 'county'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad data\n",
    "df = df[~(df == -666666666.0).any(axis=1)]\n",
    "df = df[~(df == 666668684).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to df_new\n",
    "df[\"Population Density\"] = df[\"Population\"]/df[\"Land-Sq-Mi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction Matrix Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# data = pandas.read_csv(url, names=names)\n",
    "# df_test = df_new.drop(\"median_home_value\", axis=1)\n",
    "correlations = df.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = numpy.arange(0,19,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "names = ['Population', 'Median Age', 'Household Income', 'median_home_value',\n",
    "       'Per Capita Income', 'Masters holders', 'Bachelor holders',\n",
    "       'Median gross rent', 'Poverty Count', 'Poverty Rate', 'Unemployment',\n",
    "       'Unemployment rate', 'pop_arc/eng', 'pop_stem', 'pop_tech', 'pop_biz',\n",
    "       'house_age', 'Land-Sq-Mi', 'Population Density']\n",
    "# ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop correlated feature columns\n",
    "df_test_col_removed = df.drop(['Unemployment', \"Poverty Count\", 'pop_tech', 'Bachelor holders', 'pop_biz','pop_stem', 'Land-Sq-Mi' ], axis=1)\n",
    "df_test_col_removed.columns\n",
    "df_test_col_removed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_col_removed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the dataset to csv\n",
    "# df_test_col_removed.to_csv(\"clean_house_value_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction Matrix Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# data = pandas.read_csv(url, names=names)\n",
    "# df_test = df_new.drop(\"median_home_value\", axis=1)\n",
    "correlations = df_test_col_removed.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = numpy.arange(0,12,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "names = ['Population', 'Median Age', 'Household Income', 'median_home_value',\n",
    "       'Per Capita Income', 'Masters holders', 'Median gross rent',\n",
    "       'Poverty Rate', 'Unemployment rate', 'pop_arc/eng',\n",
    "       'house_age', 'Population Density']\n",
    "# ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "X = df_test_col_removed.drop('median_home_value', axis=1)\n",
    "y = df_test_col_removed[\"median_home_value\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for Population\n",
    "plt.scatter(X[\"Population\"], y)\n",
    "plt.xlabel(\"Population\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for Median Age\n",
    "plt.scatter(X[\"Median Age\"], y)\n",
    "plt.xlabel(\"Median Age\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for Household Income\n",
    "plt.scatter(X[\"Household Income\"], y)\n",
    "plt.xlabel(\"Household Income\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for Per Capita Income\n",
    "plt.scatter(X[\"Per Capita Income\"], y)\n",
    "plt.xlabel(\"Per Capita Income\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for 'Masters holders'\n",
    "plt.scatter(X['Masters holders'], y)\n",
    "plt.xlabel('Masters holders')\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for 'Masters holders'\n",
    "plt.scatter(X['Masters holders'], y)\n",
    "plt.xlabel('Masters holders')\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for Poverty Rate\n",
    "plt.scatter(X[\"Poverty Rate\"], y)\n",
    "plt.xlabel(\"Poverty Rate\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for Unemployment Rate\n",
    "plt.scatter(X[\"Unemployment rate\"], y)\n",
    "plt.xlabel(\"Unemployment rate\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for pop_arc/eng\n",
    "plt.scatter(X[\"pop_arc/eng\"], y)\n",
    "plt.xlabel(\"pop_arc/eng\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend for Population Density\n",
    "plt.scatter(X[\"house_age\"], y)\n",
    "plt.xlabel(\"house_age\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trend for Population Density\n",
    "plt.scatter(X[\"Population Density\"], y)\n",
    "plt.xlabel(\"Population Density\")\n",
    "plt.ylabel(\"House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn's `train_test_split` to split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data with SKLearn StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting our model with training data\n",
    "model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with test data\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by Calculate the following for the test data\n",
    "# 1. Calculate the mean_squared_error (mse)\n",
    "# 2. the r-squared value (r2)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = model.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# Or by calling the `score` method on the model to show the r2 score\n",
    "model.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "plt.scatter(model.predict(X_train_scaled), model.predict(X_train_scaled) - y_train_scaled, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_scaled), model.predict(X_test_scaled) - y_test_scaled, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_scaled.min(), xmax=y_test_scaled.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "# X_scaled_new = [[ 0.80809856,  1.35009033, -0.01890773,  0.34549878, -0.82941627, 0.2246137 ]]\n",
    "# X_scaled_new = [[ 3.48460584, -0.82941627,  0.80809856, 0.2345, 0.5678, -0.33548015, 0.2246137 ,  1.35009033]]\n",
    "# X_scaled_new = [[ 3.48460584, -0.82941627,  0.80809856,  0.34549878, -0.01890773, -0.33548015,  0.2246137 ,  1.35009033]]\n",
    "\n",
    "# X_scaled_new = [[-0.11078969,  0.51738345,  0.*2866739,  0.34154584, -0.27276221,\n",
    "#         0.98311992, -0.45964101,  0.82921035, -0.37015243, -0.01418429,\n",
    "#        -0.91011539, -0.95559417]]\n",
    "\n",
    "X_scaled_new = [[ 0.03112578,  0.78546681, -0.58000409, -0.18338835, -0.22006741,\n",
    "       -0.56337918, -0.35730793, -0.16093156,  0.13908083, -0.30457034,\n",
    "       -0.25241833]]\n",
    "prediction_scaled = model.predict(X_scaled_new)\n",
    "prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LASSO model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "lasso = Lasso(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "predictions = lasso.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = lasso.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ridge = Ridge(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = ridge.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = ridge.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ElasticNet model\n",
    "# Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elasticnet = ElasticNet(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = elasticnet.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = elasticnet.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=300)\n",
    "rf = rf.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# save the model\n",
    "filename = 'cl_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))\n",
    "\n",
    "# R2 for training data\n",
    "rf.score(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "importances_list = sorted(zip(rf.feature_importances_, X.keys()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 for testing data\n",
    "rf.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "X_scaled_new = [[ 0.03112578,  0.78546681, -0.58000409, -0.18338835, -0.22006741,\n",
    "       -0.56337918, -0.35730793, -0.16093156,  0.13908083, -0.30457034,\n",
    "       -0.25241833]]\n",
    "prediction_scaled = rf.predict(X_scaled_new)\n",
    "prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "# X_scaled_new = ([[ 0.90809856,  1.35009033, -0.01890773,  0.94549878, -0.82941627, 0 ]])\n",
    "# X_scaled_new = [[ 0.80809856,  1.35009033,  3.48460584, 0.3456,  0.34549878, -0.82941627,  0.2246137 ]]\n",
    "prediction_scaled = loaded_model.predict(X_scaled_new)\n",
    "prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = loaded_model.feature_importances_\n",
    "importances_list = sorted(zip(loaded_model.feature_importances_, X.keys()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [[17423.0,45.0,56714.0,30430.0,1353.0,975.0,8.391207,2.749240,149,49,1522.723300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
