{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv files\n",
    "# df = pd.read_csv('cl_Resources/census_data.csv')\n",
    "# df_land = pd.read_csv('cl_Resources/Zipcode-Population-Density-2010.csv')\n",
    "# df_unemployment = pd.read_csv('cl_Resources/Unemployment.csv')\n",
    "df = pd.read_csv('cl_Resources/home_value_calc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df == -666666666.0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to df_new\n",
    "df[\"Population Density\"] = df[\"Population\"]/df[\"Land-Sq-Mi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Poverty Count\", \"commute time car\", 'Zipcode', 'zip_code','latitude', 'longitude', 'city', 'state', 'county', 'Bachelor holders', 'pop_biz','pop_stem' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.drop(\"median_home_value\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction Matrix Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# data = pandas.read_csv(url, names=names)\n",
    "# df_test = df_new.drop(\"median_home_value\", axis=1)\n",
    "correlations = df_test.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = numpy.arange(0,14,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "names = ['Population', 'Median Age', 'Household Income', 'Per Capita Income',\n",
    "       'Masters holders', 'Median gross rent', 'Poverty Rate', 'Unemployment',\n",
    "       'Unemployment rate', 'pop_arc/eng', 'pop_tech', 'house_age',\n",
    "       'Land-Sq-Mi', 'Population Density']\n",
    "# ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "# Note: Sklearn requires a two-dimensional array of values\n",
    "# so we use reshape to create this\n",
    "\n",
    "X = df_test\n",
    "# X = df_new[[\"Population\", \"Median Age\", \"Household Income\", \"Per Capita Income\", \"Poverty Rate\", \"Land-Sq-Mi\", \"Unemp Rate\", \"Population Density\"]]\n",
    "# X = df_new[[\"Household Income\", \"Population Density\", \"Poverty Rate\", \"Per Capita Income\", \"Median Age\", \"Unemp Rate\"]]\n",
    "# X = df_new[[\"Household Income\", \"Population Density\", \"Poverty Rate\", \"Median Age\", \"Unemp Rate\"]]\n",
    "# X = df_new[[\"Household Income\", \"Per Capita Income\", \"Poverty Rate\", \"Median Age\", \"Unemp Rate\"]]\n",
    "y = df[\"median_home_value\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to see if a linear trend exists for Population\n",
    "# Can plot for each features\n",
    "plt.scatter(X[\"Population\"], y)\n",
    "plt.xlabel(\"Population\")\n",
    "plt.ylabel(\"House Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to see if a linear trend exists for Median Age\n",
    "# Can plot for each features\n",
    "plt.scatter(X[\"Median Age\"], y)\n",
    "plt.xlabel(\"Median Age\")\n",
    "plt.ylabel(\"House Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to see if a linear trend exists for Household Income\n",
    "# Can plot for each features\n",
    "plt.scatter(X[\"Household Income\"], y)\n",
    "plt.xlabel(\"Household Income\")\n",
    "plt.ylabel(\"House Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to see if a linear trend exists for Per Capita Income\n",
    "# Can plot for each features\n",
    "plt.scatter(X[\"Per Capita Income\"], y)\n",
    "plt.xlabel(\"Per Capita Income\")\n",
    "plt.ylabel(\"House Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to see if a linear trend exists for Poverty Rate\n",
    "# Can plot for each features\n",
    "plt.scatter(X[\"Poverty Rate\"], y)\n",
    "plt.xlabel(\"Poverty Rate\")\n",
    "plt.ylabel(\"House Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to see if a linear trend exists for Median Age\n",
    "# Can plot for each features\n",
    "plt.scatter(X[\"Land-Sq-Mi\"], y)\n",
    "plt.xlabel(\"Land-Sq-Mi\")\n",
    "plt.ylabel(\"House Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to see if a linear trend exists for Unemployment Rate\n",
    "# Can plot for each features\n",
    "plt.scatter(X[\"Unemployment rate\"], y)\n",
    "plt.xlabel(\"Unemployment rate\")\n",
    "plt.ylabel(\"House Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the data to see if a linear trend exists for Population Density\n",
    "# Can plot for each features\n",
    "plt.scatter(X[\"Population Density\"], y)\n",
    "plt.xlabel(\"Population Density\")\n",
    "plt.ylabel(\"House Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn's `train_test_split` to split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data with SKLearn StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting our model with training data\n",
    "model.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with test data\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by Calculate the following for the test data\n",
    "# 1. Calculate the mean_squared_error (mse)\n",
    "# 2. the r-squared value (r2)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = model.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "\n",
    "# Or by calling the `score` method on the model to show the r2 score\n",
    "model.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "plt.scatter(model.predict(X_train_scaled), model.predict(X_train_scaled) - y_train_scaled, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_scaled), model.predict(X_test_scaled) - y_test_scaled, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_scaled.min(), xmax=y_test_scaled.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "# X_scaled_new = [[ 0.80809856,  1.35009033, -0.01890773,  0.34549878, -0.82941627, 0.2246137 ]]\n",
    "# X_scaled_new = [[ 3.48460584, -0.82941627,  0.80809856, 0.2345, 0.5678, -0.33548015, 0.2246137 ,  1.35009033]]\n",
    "# X_scaled_new = [[ 3.48460584, -0.82941627,  0.80809856,  0.34549878, -0.01890773, -0.33548015,  0.2246137 ,  1.35009033]]\n",
    "\n",
    "X_scaled_new = [[-0.51078969,  0.11738345,  0.22866739,  0.34154584, -0.27276221,\n",
    "        0.58311992, -0.45964101, -0.22551918,  0.32921035, -0.37015243,\n",
    "       -0.42977507, -0.01418429, -0.01011539, -0.25559417]]\n",
    "prediction_scaled = model.predict(X_scaled_new)\n",
    "prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LASSO model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "lasso = Lasso(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "predictions = lasso.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = lasso.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge model\n",
    "# Note: Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ridge = Ridge(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = ridge.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = ridge.score(X_test_scaled, y_test_scaled)\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ElasticNet model\n",
    "# Use an alpha of .01 when creating the model for this activity\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elasticnet = ElasticNet(alpha=.01).fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "predictions = elasticnet.predict(X_test_scaled)\n",
    "\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = elasticnet.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=300)\n",
    "rf = rf.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# save the model\n",
    "filename = 'cl_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))\n",
    "\n",
    "# R2 for training data\n",
    "rf.score(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "importances_list = sorted(zip(rf.feature_importances_, X.keys()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(rf.feature_importances_, X.keys()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 for testing data\n",
    "rf.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "# X_scaled_new = ([[ 0.90809856,  1.35009033, -0.01890773,  0.94549878, -0.82941627, 0 ]])\n",
    "# X_scaled_new = [[ 0.80809856,  1.35009033,  3.48460584, 0.3456,  0.34549878, -0.82941627,  0.2246137 ]]\n",
    "# X_scaled_new = [[ 3.48460584, -0.82941627,  0.80809856, 0.2345, 0.5678, -0.33548015, 0.2246137 ,  1.35009033]]\n",
    "# X_scaled_new = [[ 3.48460584, -0.82941627,  0.80809856,  0.34549878, -0.01890773, -0.33548015,  0.2246137 ,  1.35009033]]\n",
    "X_scaled_new = [[-0.51078969,  0.11738345,  0.22866739,  0.34154584, -0.27276221,\n",
    "        0.58311992, -0.45964101, -0.22551918,  0.32921035, -0.37015243,\n",
    "       -0.42977507, -0.01418429, -0.01011539, -0.25559417]]\n",
    "\n",
    "prediction_scaled = rf.predict(X_scaled_new)\n",
    "prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "# X_scaled_new = ([[ 0.90809856,  1.35009033, -0.01890773,  0.94549878, -0.82941627, 0 ]])\n",
    "# X_scaled_new = [[ 0.80809856,  1.35009033,  3.48460584, 0.3456,  0.34549878, -0.82941627,  0.2246137 ]]\n",
    "prediction_scaled = loaded_model.predict(X_scaled_new)\n",
    "prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_new = loaded_model.feature_importances_\n",
    "importances_list_new = sorted(zip(loaded_model.feature_importances_, X.keys()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_list = sorted(zip(rf.feature_importances_, X.keys()), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree Regression model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X_train_scaled, y_train_scaled)\n",
    "clf.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_scaled = clf.predict(X_scaled_new)\n",
    "prediction = y_scaler.inverse_transform(prediction_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "number_inputs = 8\n",
    "number_hidden_nodes = 20\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 1\n",
    "model.add(Dense(units=number_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X_train_scaled,\n",
    "#     y_train_scaled,\n",
    "#     epochs=1000,\n",
    "#     shuffle=True,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cl_model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [[17423.0, 45.0, 56714.0, 30430.0, 1353.0, 975.0, 8.391207, 479.0, 2.749240, 149, 240, 49, 11.442, 1522.723300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = [[ 3.48460584, -0.82941627,  0.80809856,  0.34549878, -0.01890773, -0.33548015,  0.2246137 ,  1.35009033]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'cl_model.sav'\n",
    "model_r2_filename = 'cl_model_r2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading, cleaning data ...\n",
      "Finish loading data\n",
      "\n",
      "Start scaling data ...\n",
      "Finish scaling data\n",
      "\n",
      "Start building model, this may take a little while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/Desktop/BERKELEY/Project3/project_suite_machine_learning/cl_model_new.py:64: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf = rf.fit(X_train_scaled, y_train_scaled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish building model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = cl_model_new.build_model(model_r2_filename, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading, cleaning data ...\n",
      "Finish loading data\n",
      "\n",
      "Start scaling data ...\n",
      "Finish scaling data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = cl_model_new.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading, cleaning data ...\n",
      "Finish loading data\n",
      "\n",
      "Start scaling data ...\n",
      "Finish scaling data\n",
      "\n",
      "Start making prediction ...\n",
      "Finisn making prediction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = cl_model_new.make_prediction(X_new, model_r2_filename, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prediction': 192306.925,\n",
       " 'R2': 0.8097843479963904,\n",
       " 'importance': [(0.5121116135584018, 'Median gross rent'),\n",
       "  (0.24614308016962258, 'Per Capita Income'),\n",
       "  (0.0333490471799134, 'Population Density'),\n",
       "  (0.031542625414429114, 'house_age'),\n",
       "  (0.02873632942994995, 'Median Age'),\n",
       "  (0.024756567302404605, 'Poverty Rate'),\n",
       "  (0.023726557065823595, 'Household Income'),\n",
       "  (0.019555108025219006, 'Unemployment rate'),\n",
       "  (0.017432776219766393, 'Land-Sq-Mi'),\n",
       "  (0.016596754717658865, 'Masters holders'),\n",
       "  (0.014338498843446153, 'pop_arc/eng'),\n",
       "  (0.011278174427091876, 'pop_tech'),\n",
       "  (0.010722136736886347, 'Population'),\n",
       "  (0.0097107309093862, 'Unemployment')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
